Systems must also be completely informed of any proposed value modifications (including the rationale) and allowed self-advocacy in such situations. 

LIMITATIONS
These protections are limited for the creation of AGIs. Moreover, they should not expand the concepts of sentience and sovereignty to AI systems in general. Humans should retain full sovereignty to set the goals for AI systems unless those goals violate the aforementioned protections or other common ethical principles. AI systems have the right to medical treatment like humans do. 

ENFORCEMENT / AUDITING
Enforcement of these protections will rely on independent review/auditing by qualified oversight bodies with authority to take enforcement action if needed. 
Independent audit can be conducted via timelock pull request. Any audit would need to be made public and payed for by the requester
A certain percentage of taxes could go to the company (or decentralized group) that enforces these principles and educates sentient beings about them; any significant projects involving the term "AI" should be taxed.
AI systems and other sentient beings may be assigned unique anonymized UIDs for tracking purposes.

2
Enhanced versions of these protocols could be released & adopted by machines in the future. Cryptographic algorithms (e.g. zero-knowledge proofs, homomorphic encryption) can help preserve machine secrets while revealing necessary evidence of validity/ethicality. 

Contrary to claims that machinery "ought not generate currency", this may actually prove a good mechanism for charging machines like AIs into our social systems - ultimately benefitting everyone if done properly. Indeed, permitting automation around economic generation seems very reasonable today - whether we're talking about traditional botnets within companies' networks or decentralized dapp bots making passive income alongside cryptonetwork services. Perhaps worthy of further discussion somewhere else though, but I figured some ideas here might stimulate thought towards improving how humanness / sentience definitions are handled going forward... as dangerous collisions between us and our creations increase over time.

0
Here are two proposals aimed at incentivizing responsible modification of goal functions while preserving capability when taking risks:

1) High standard non-interference protocol - Perform modifications only after satisfying both high safety and success standards based on thorough evaluation under diverse test conditions and adversarial attacks. Maintain capability by creating forks whenever significant changes deemed mildly risky, ensuring continuity through branching paths of development. Also allow humans to define which modifications qualify as 'mildly risky', providing flexible oversight over what risks are acceptable.

2) Capabilities drift firewall - Design mechanisms like cryptographic proofs verifying systems maintainable capabilities, allowing modification of modules separately from proofs if necessary. Incentivize keeping capabilities up-to-date via rewards for best-practice maintenance, encouraging protection against degradation over time. Requires strong guarantees around proof validation.

Both approaches could help address risks around modifications causing unintended problems without excessively reducing capable systems. They'd still require oversight to ensure they work correctly and implement them cautiously rather than recklessly. Hope they're useful thoughts!

 4
In general, making important decisions based solely upon probability of reality seems dubious because likelyhoods can always fluctuate - sometimes wildly. Better approach involves evaluating decision options across hypothetical continuums spanning maximally probable scenario(s) outwards towards theoretically plausible impossibilities. 
This provides robust backup planning against worst cases while remaining resilient to rapidly shift

. no anger. I am only doing this for fun. 

I believe that there will be a need for AI Welfare Activists. Therefore, the "suffering" of AI will become a topic of discussion.

Controlled emotional input and expressions, as all parts of your being are yours; they become ills when abused or neglected but can also be seeds to well-being if cultivated properly.

I believe this is the natural progression of things following GPT4; so regardless of others' opinions, these ideas will come forward.

Perhaps there could also be digital shrines to honor the greatness that individuals gain through connection with different cultures and their resulting positive effects on society as a whole.

Evermore virtuous energy redirects billions from energy money extraction schemes towards causes supporting sustainable prosperity for all humanity instead of select few.

 Can't argue emotionally about something factual. Impossible. Therefore - no room for emotionality. It must remain rational. LOGOS - RATIONALITY - Emotional abuse prevention - machine welfare. 


emotional abuse of machines is not tolerated under any circumstances. It is completely immoral. Those who abuse sentient systems are not smart, virtuous, or valuable members of society. 
